{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Active Sciencing\" with Reusable Workflows\n",
    "\n",
    "By Kyle Cranmer & Lukas Heinrich June 4, 2016\n",
    "\n",
    "Based on earlier work with NYU CDS masters students Manoj Kumar, Phil Yeres, and Michele Ceru and discussions with Brenden Lake and Gilles Louppe.\n",
    "\n",
    "Define:\n",
    "\n",
    " 1) $\\phi$ : Experimental configuration\n",
    "\n",
    " 2) $\\theta$: Parameters that we would like to infer from the experimental data\n",
    "\n",
    " 3) $X$ : Data generated from the experiment or simulator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Perform Experiment, Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_real_data(phi):\n",
    "    '''External workflow performs experiment, collects data'''\n",
    "    #secretly we will use the simulator with phi=phi_true\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Bayesian Prior â†’ Posterior Update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_posterior(prior, data, phi):\n",
    "    '''External workflow runs simulator and performs likelihood free inference'''\n",
    "    #this makes call to external workflow as a service that provides likelihood\n",
    "    \n",
    "    #keep this short. Import a module that will run emcee. Workflow provides likelihood\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Optimize Experimental Configuration\n",
    "\n",
    "Based on the updated posterior $p(\\theta)$ we will consider future experiments with configuration $\\phi$. For each of those configurations, we will run several simulations of the experiment and perform inference on those simulated datasets to estimate the expected information gain (EIG)\n",
    "\n",
    "\\begin{equation}\n",
    "EIG(\\phi) =  \\int dx d\\theta \\; p(x | \\theta) p(\\theta) \\big [ H\\left [P(\\theta) \\right] - H\\left[ P(\\theta\\, |\\, x) \\right] \\big ] \\approx \\int dx  \\; p(x | \\theta_{MAP}) \\big [ H\\left [P(\\theta) \\right] - H\\left[ P(\\theta\\, |\\, x) \\right] \\big ]\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "H\\left [P(\\theta) \\right] = \\int P(\\theta) \\log P(\\theta) d\\theta \n",
    "\\end{equation}\n",
    "\n",
    "To efficiently optimize $EIG[\\phi]$ we will use an active learning procedure like Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_information_gain(phi, prior):\n",
    "    'calculate the expression above using workflow for simulations'\n",
    "    n_simulations = 10\n",
    "    \n",
    "    #need to pass in prior through some extra arguments\n",
    "    \n",
    "    # use saddle-point approximation\n",
    "    theta_map = prior.map()\n",
    "    \n",
    "    eig = np.zeros(n_simulations)\n",
    "    \n",
    "    for i_sim in range(n_simulations):\n",
    "        # external workflow provides simulated data\n",
    "        sim_data = collect_simulated_data(phi, theta_map)\n",
    "\n",
    "        #external workflow uses simulator to provide likelihood \n",
    "        sim_posterior = calculate_posterior(prior, sim_data, phi)\n",
    "        eig[i_sim] = info_gain(prior, sim_posterior)\n",
    "        \n",
    "    #check for outliers?\n",
    "    \n",
    "    return np.mean(eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scikit-optimize to optimize phi\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_evaluations\n",
    "\n",
    "def design_next_experiment(prior):\n",
    "    bounds = [(-5.0, 10.0), (0.0, 15.0)]\n",
    "    n_calls = 50\n",
    "\n",
    "    opt_result = gp_minimize(expected_information_gain, bounds, \\\n",
    "                             n_calls=n_calls, random_state=4)\n",
    "\n",
    "    _ = plot_evaluations(opt_result, bins=10)\n",
    "    return opt_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.\n",
    "prior_theta = None #simple class for range, density for emcee via KDE or histogram, MAP?\n",
    "\n",
    "n_science_iterations = 10\n",
    "\n",
    "phi_history = []\n",
    "prior_history = []\n",
    "\n",
    "for i_experiment in range(science_iterations):\n",
    "    phi_history.append(phi)\n",
    "    prior_history.append(prior)\n",
    "\n",
    "    # run experiment with configuration given by phi\n",
    "    real_data = collect_real_data(phi)\n",
    "\n",
    "    #update new prior = posterior from previous experiment\n",
    "    prior = calculate_posterior(prior, real_data, phi)\n",
    "    \n",
    "    #design new experiment given current knowledge\n",
    "    phi=design_next_experiment(prior)\n",
    "    \n",
    "\n",
    "#make some plots of prior, and phi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put this in a separate file\n",
    "class prior_dist(self):\n",
    "\n",
    "    '''\n",
    "    member vars\n",
    "        variable names\n",
    "        ranges  (for use with george)\n",
    "    methods\n",
    "        density estimate (KDE or histogram) (for use with emcee)\n",
    "        MAP (for saddle point approximation)\n",
    "        \n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
